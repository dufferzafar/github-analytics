{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.types as spark_types\n",
    "\n",
    "import utils\n",
    "\n",
    "spark = SparkSession.builder.master(\"spark://vm1:7077\").appName(\"Cluster Code - Zafar\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing to see if everything is okay\n",
    "commits = utils.read_csv(spark, \"hdfs:/commits_new.csv\")\n",
    "commits.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of source & fork repositories of users (shouldn't be run again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects =  utils.read_csv(spark, \"hdfs:/projects.csv\", \"projects_new.csv\")\n",
    "\n",
    "# This file has now been replaced with a new version\n",
    "user_more =  utils.read_csv(spark, \"hdfs:/user_more.csv\")\n",
    "\n",
    "# Find source repos\n",
    "df4 = (\n",
    "    projects\n",
    "    .where((projects.deleted == 0) & (projects.forked_from.isNull()))\n",
    "    .groupby(\"owner_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"repos_source\")\n",
    "    .withColumnRenamed(\"owner_id\", \"user_id\")\n",
    ")\n",
    "\n",
    "# Find forks\n",
    "df6 = (\n",
    "    projects\n",
    "    .where((projects.deleted == 0) & (projects.forked_from.isNotNull()))\n",
    "    .groupby(\"owner_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"repos_forks\")\n",
    "    .withColumnRenamed(\"owner_id\", \"user_id\")\n",
    ")\n",
    "\n",
    "# Join Data\n",
    "df5 = user_more.join(df4, \"user_id\", \"full\").join(df6, \"user_id\", \"full\")\n",
    "\n",
    "# Write to local directorya\n",
    "df5.write.csv(\n",
    "    \"/user_more_2\",\n",
    "    mode=\"overwrite\",\n",
    "    nullValue=\"\\\\N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue Punchcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+----+--------+\n",
      "|year|month| day|hour|   count|\n",
      "+----+-----+----+----+--------+\n",
      "|null| null|null|null|54086297|\n",
      "+----+-----+----+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "issues = utils.read_csv(spark, \"hdfs:/issues.csv\")\n",
    "\n",
    "df5 = (\n",
    "    issues\n",
    "    .where(\n",
    "        issues.created_at.isNotNull()\n",
    "    )\n",
    "    .select(\n",
    "        F.year('created_at').alias('year'), \n",
    "        F.month('created_at').alias('month'), \n",
    "        F.dayofmonth('created_at').alias('day'), \n",
    "        F.hour('created_at').alias('hour')\n",
    "    )\n",
    "   .groupBy('year', 'month', 'day', 'hour')\n",
    "   .count()\n",
    ")\n",
    "\n",
    "df5.limit(10).show()\n",
    "\n",
    "# df5.explain()\n",
    "# df5.coalesce(1).write.json(\"hdfs:/issue_punchcard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Commits of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits = utils.read_csv(spark, \"hdfs:/commits_new.csv\")\n",
    "\n",
    "res = (\n",
    "    commits\n",
    "    .groupby(\"author_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"commits_authored\")\n",
    "    .withColumnRenamed(\"author_id\", \"user_id\")\n",
    ")\n",
    "\n",
    "res.write.csv(\n",
    "    \"hdfs:/user_commit_count\",\n",
    "    mode=\"overwrite\",\n",
    "    nullValue=\"\\\\N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Commits of every project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commits = utils.read_csv(spark, \"hdfs:/commits_new.csv\")\n",
    "\n",
    "res = (\n",
    "    commits\n",
    "    .groupby(\"project_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"total_commits\")\n",
    ")\n",
    "\n",
    "res.write.csv(\n",
    "    \"hdfs:/project_commit_count\",\n",
    "#     mode=\"overwrite\",\n",
    "    nullValue=\"\\\\N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Commits on a project not authored by Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits = utils.read_csv(spark, \"hdfs:/commits_new.csv\")\n",
    "projects = utils.read_csv(spark, \"hdfs:/projects_new.csv\")\n",
    "\n",
    "commits.createOrReplaceTempView(\"commits\")\n",
    "projects.createOrReplaceTempView(\"projects\")\n",
    "\n",
    "q = \"\"\"\n",
    "    SELECT C.project_id as project_id, COUNT(*) as total_commits_by_others\n",
    "    FROM commits as C, projects as P\n",
    "    WHERE C.project_id = P.id\n",
    "    AND C.author_id <> P.owner_id\n",
    "    GROUP BY C.project_id\n",
    "\"\"\"\n",
    "\n",
    "res = spark.sql(q)\n",
    "\n",
    "res.write.csv(\n",
    "    \"hdfs:/project_commit_others_count\",\n",
    "#     mode=\"overwrite\",\n",
    "    nullValue=\"\\\\N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of commits of a user made on repositories not owned by them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    SELECT C.author_id as user_id, \n",
    "           COUNT(*) as total_commits_on_other_repos\n",
    "\n",
    "    FROM commits as C, projects as P\n",
    "\n",
    "    WHERE C.project_id = P.id\n",
    "    AND C.author_id <> P.owner_id\n",
    "\n",
    "    GROUP BY C.author_id\n",
    "\"\"\"\n",
    "\n",
    "res = spark.sql(q)\n",
    "\n",
    "res.write.csv(\n",
    "    \"hdfs:/user_commit_others_count\",\n",
    "#     mode=\"overwrite\",\n",
    "    nullValue=\"\\\\N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Top\" Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+--------------------+---------+---------+-------+------------+-----------+---------+---------------+------+-----+-------+--------------+\n",
      "|user_id|        login|             company|following|followers|starred|repos_source|repos_forks|has_stars|contributess_to|issues|pulls|commits|commits_others|\n",
      "+-------+-------------+--------------------+---------+---------+-------+------------+-----------+---------+---------------+------+-----+-------+--------------+\n",
      "|   3871| sindresorhus|@avajs @chalk @ye...|      188|    15755|   2274|         974|        142|   226099|            565|  3080|  108|  26326|          8341|\n",
      "|6498757| FreeCodeCamp|                null|        1|      110|      6|          95|          5|   214583|           null|     1| null|     18|          null|\n",
      "| 376498|           Tj|                Apex|      175|    25827|    966|         238|         81|   114326|            138|   873| null|   4922|          3539|\n",
      "| 234594|       docker|                null|        5|        3|      8|         121|         10|   109060|              1|     1| null|     12|          null|\n",
      "|    896|  JakeWharton|        Square, Inc.|       24|    30161|    261|          86|         24|    82059|             58|  1125|  168|  16014|         11195|\n",
      "|    796| kennethreitz|              Heroku|      224|    13360|    919|         119|         37|    76984|            105|   473|   41|  12559|          6860|\n",
      "|   1199|     substack|    bits cooperative|      238|    11397|    277|         771|        195|    74744|            223|   291|   43|  19767|          4870|\n",
      "|  17717|       getify|    Getify Solutions|        9|     6360|    254|          44|          5|    73675|             15|   437|    4|   3116|           155|\n",
      "| 274322|          vhf|                null|       50|     2449|    531|          63|         69|    73353|             35|   135|    9|   5234|          1426|\n",
      "| 215522|     Yalantis|                null|        4|     null|      4|          65|          2|    68689|           null|  null| null|   null|          null|\n",
      "|   1954|  visionmedia|                null|      157|    11714|    624|         160|         63|    67825|             80|  2343|   40|  29853|         22294|\n",
      "|1123322|        Apple|                null|     null|        7|   null|          37|          1|    66930|           null|  null| null|   null|          null|\n",
      "|  15119| robbyrussell|   Planet Argon, LLC|       33|     1933|     50|           8|         26|    62104|             18|    39| null|   2108|          1122|\n",
      "| 667293|       nodejs|                null|     null|       21|   null|         158|          9|    59809|           null|  null| null|   null|          null|\n",
      "|3752431|  donnemartin|                null|        9|     1072|    976|          37|          5|    58763|              7|   176|    3|   4597|           458|\n",
      "| 293854|         Zeit|                null|        2|     null|   null|          64|          3|    57722|           null|  null| null|   null|          null|\n",
      "|   6240|   addyosmani|              Google|      243|    24604|    522|         147|        154|    55154|            308|  1195|   36|  10762|          6865|\n",
      "| 417948|      gaearon|            Facebook|      177|    13007|   1172|          59|        177|    53475|             69|  1079|   38|  10576|          5387|\n",
      "|2205410|kamranahmedse|             tajawal|       65|      177|    569|          43|         13|    50494|             16|    43| null|   1610|           187|\n",
      "|2813904|      jwasham|                null|        7|      805|     80|          31|          7|    49707|              1|    15| null|   1157|           149|\n",
      "|1147949|     wasabeef|    CyberAgent, Inc.|       41|     3341|    819|          22|          7|    49650|              6|     6| null|   1495|           153|\n",
      "|   3816|      daneden|            Facebook|      101|     3738|     61|          45|         10|    49553|             18|    30|    2|   2409|           459|\n",
      "|   7125|    jashkenas|The New York Time...|     null|    11410|      6|          17|       null|    49270|             24|    91|    1|  10622|          9589|\n",
      "|1963067|      tencent|                null|     null|       14|      5|          38|          2|    48844|           null|  null| null|      2|             2|\n",
      "|2629032|     typicode|                null|     null|     1014|    166|          29|         19|    47616|             11|    33|    1|   3626|            94|\n",
      "|   5260|      antirez|          Redis Labs|        2|     7215|     41|          54|          3|    47226|             13|   185| null|  12361|          5178|\n",
      "| 204125|      elastic|                null|        6|        9|     20|         187|         19|    46946|              6|  null| null|     19|             9|\n",
      "|   5203|     torvalds|    Linux Foundation|     null|    52722|      1|           5|          2|    46605|            105|     1| null|  48823|         39566|\n",
      "| 616741|       ruanyf|                null|     null|    14701|    124|          36|         12|    45361|             11|     4|    1|   4619|           390|\n",
      "|  13009|     mbostock|                null|       13|    14928|     29|          53|         18|    44739|             35|  1284|  137|  15904|         11370|\n",
      "|   2532|       mrdoob|                null|      110|     9651|     75|          32|         17|    44493|             31|   115|   11|  12837|          3234|\n",
      "|  10227|       feross|Study Notes, WebT...|      199|     5577|    854|         163|        153|    43445|            155|  1582|   13|  17300|          2083|\n",
      "| 129526|     bevacqua| JavaScript @elastic|      176|     2954|    339|         186|        102|    42447|             62|   201|    6|  14245|          3267|\n",
      "|   6258|      necolas|             Twitter|       27|     5799|    289|          31|         34|    42179|             70|  1079|   31|   4322|          2596|\n",
      "| 139710|    toddmotto|Telerik, Ultimate...|       43|     3272|    133|          59|         23|    41596|             37|    50|    6|   3454|          1319|\n",
      "|  10321|      blueimp|         blueimp.net|     null|     3237|     27|          52|          6|    40990|              9|    11|    1|   4155|          1839|\n",
      "|   2163|      hakimel|              Slides|       30|     7760|     54|          21|          3|    40870|             16|    42| null|   2216|           778|\n",
      "|   8293|        spf13|             @Google|       81|     2905|    572|          35|         54|    40784|             54|    68|    4|   1938|           466|\n",
      "|  43814|    justjavac|    @Flarum-Chinese |      129|     5685|    728|          34|         25|    40403|             13|   118| null|   3014|           415|\n",
      "| 490958|       jekyll|                null|     null|     null|   null|          53|       null|    40031|           null|  null| null|   null|          null|\n",
      "|2574738|        vinta|       @StreetVoice |      122|     1512|   1958|          26|         18|    39832|             10|   188| null|   2239|           194|\n",
      "|   3569|    mitsuhiko|                null|       21|     8801|     52|         138|         55|    38750|             50|   478|   15|  13938|          8735|\n",
      "| 122176|      astaxie|               Apple|       18|     6334|    100|          34|         40|    37919|             36|    62|    1|   5121|          2264|\n",
      "|1279090|        Realm|                null|     null|     null|   null|          31|          5|    37826|           null|  null| null|   null|          null|\n",
      "| 501475|        jlevy|                null|       87|      684|    885|           8|         13|    37551|              3|   181|    2|   1144|           391|\n",
      "|  11213| nicklockwood|     Charcoal Design|     null|     4179|     32|          64|         23|    37365|             20|    13|    2|   3519|          1750|\n",
      "|  76839|     Firebase|                null|        8|       39|     10|         147|         20|    37320|              1|  null| null|   null|          null|\n",
      "|   5823|        tpope|                null|       25|     9149|     19|          80|          9|    36680|             18|    55|   18|   5895|          2683|\n",
      "|   1570|      defunkt|            @github |      230|    18522|    139|          78|         29|    36487|             61|   170|    6|   5068|          4073|\n",
      "|3582041|     electron|                null|     null|     null|   null|          55|          1|    35206|           null|  null| null|      2|          null|\n",
      "+-------+-------------+--------------------+---------+---------+-------+------------+-----------+---------+---------------+------+-----+-------+--------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_more = utils.read_csv(spark, \"hdfs:/users_more.csv\")\n",
    "users = utils.read_csv(spark, \"hdfs:/users.csv\")\n",
    "\n",
    "users = (\n",
    "    users\n",
    "    .where(\n",
    "          (users.type == \"USR\")\n",
    "        & (users.deleted == 0)\n",
    "        & (users.fake == 0)\n",
    "    )\n",
    "    .withColumnRenamed(\"id\", \"user_id\")\n",
    "    .select(\"user_id\", \"login\", \"company\")\n",
    ")\n",
    "\n",
    "user_new = users.join(users_more, \"user_id\", \"left\")\n",
    "\n",
    "top = (\n",
    "    user_new\n",
    "#     .orderBy(\"followers\", ascending=False)\n",
    "    .orderBy(\"has_stars\", ascending=False)\n",
    ")\n",
    "\n",
    "top.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Top\" Users from India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+--------------------+--------------+---------+---------+---------+--------------+------+-----+-------+--------------+\n",
      "| user_id|            login|             company|         state|     city|followers|has_stars|contributes_to|issues|pulls|commits|commits_others|\n",
      "+--------+-----------------+--------------------+--------------+---------+---------+---------+--------------+------+-----+-------+--------------+\n",
      "|   23402|          hemanth|             @paypal|          null|     null|     1209|    14032|           148|   505|   39|   5212|          1420|\n",
      "| 6310255|amitshekhariitbhu|          Bobble App|         Delhi|New Delhi|      311|    10360|             7|    10| null|   1581|           509|\n",
      "| 3408218|    sachinchoolur|Available for New...|     Karnataka|Bengaluru|      255|     9799|             3|     1|    1|    901|            53|\n",
      "|  163695|        chinchang|           @wingify |         Delhi|    Delhi|      468|     9326|             9|   136|    2|   1647|           245|\n",
      "| 5769465|          nisrulz|      @omnilabs-inc |       Haryana|  Gurgaon|      320|     8024|             1|    47|    2|   2788|           278|\n",
      "| 6559743|        aritraroy|                null|          null|     null|      189|     8005|          null|    32| null|    285|             5|\n",
      "| 1343504|        sameersbn|                null|           Goa|     null|      582|     7706|            23|    69|   10|  15917|          4680|\n",
      "| 6880792|   kailashahirwar|                null|     Karnataka|Bengaluru|        4|     7206|          null|  null| null|     45|            14|\n",
      "| 5107602|           iCHAIT|                null|          null|     null|      129|     7143|             5|    53|    8|   1363|           498|\n",
      "| 2600239|      dhamaniasad|                null|   Maharashtra|   Nagpur|       72|     7089|            39|    41| null|   1325|           173|\n",
      "| 5540963|          naman14|                null|         Delhi|New Delhi|      466|     6818|             5|     5|    1|   1320|           453|\n",
      "|   26271|         sitaramc|                null|Andhra Pradesh|Hyderabad|      335|     6306|             5|    12| null|   2171|           899|\n",
      "|   39721|    threepointone|                null|     Karnataka|Bengaluru|      346|     5445|            14|   167|    3|   2648|           194|\n",
      "|  300567|      siddharthkp|                null|     Karnataka|Bengaluru|       46|     5287|            13|   137|    1|   2398|           133|\n",
      "|  428875|       kovidgoyal|                null|   Maharashtra|   Mumbai|      244|     4978|             4|    62|   16|  29601|          3899|\n",
      "| 6131656|            adtac|                null|    Tamil Nadu|  Chennai|        9|     4866|             1|   209|    3|   2040|          1214|\n",
      "| 2940742|            jarun|                null|     Karnataka|Bengaluru|      117|     4462|             1|    64| null|   3455|            78|\n",
      "| 8541687|       metagrover|           TAKE ZERO|          null|     null|       65|     3998|             4|    61| null|   1466|          1431|\n",
      "| 2822668|            ghosh|           Cleartrip|     Karnataka|Bengaluru|      102|     3967|             9|    23|    1|   1104|           104|\n",
      "|  981089|         rishabhp|                null|          null|     null|      126|     3897|             1|    26| null|    536|           428|\n",
      "|30680352|      OmkarPathak|                null|   Maharashtra|     Pune|     null|     2968|          null|     5| null|    719|            13|\n",
      "| 2566115|           webkul|              WebKul| Uttar Pradesh|    Noida|       11|     2917|             3|     3| null|    126|             8|\n",
      "|   66055|  ragunathjawahar|        Mobs & Geeks|    Tamil Nadu|  Chennai|      317|     2899|            10|    33| null|    761|           244|\n",
      "|   74479|         HashNuke|                null|     Karnataka|Bengaluru|      276|     2765|            35|    92|    4|   4985|          1123|\n",
      "|11739754|          nitin42|                null|          null|Dehra Dun|       12|     2688|             1|    43|    1|   2475|            42|\n",
      "| 5644707|    princejwesley|@nodejs Core Coll...|    Tamil Nadu|  Chennai|      123|     2651|             7|    29|    1|   1191|           170|\n",
      "| 1897977|      ajinabraham|        OpenSecurity|     Karnataka|Bengaluru|      418|     2464|            21|    87|    1|    912|           238|\n",
      "| 8786853| developer-shivam|                null|         Delhi|New Delhi|       19|     2449|             4|  null| null|    434|            17|\n",
      "| 5787841|      Ashok-Varma|           ClearTrip|          null|     null|       55|     2437|          null|    18| null|    234|             2|\n",
      "| 8392485|          hanc00l|                null|        Odisha|  Cuttack|      162|     2335|          null|     3| null|     24|             3|\n",
      "| 2446188|          yask123|          @Flipkart |         Delhi|New Delhi|      324|     2173|             7|   101| null|   2833|            43|\n",
      "| 9555236|    farizrahman4u|         @datalogai |          null|     null|      125|     2172|             4|    23|    1|   1352|           315|\n",
      "|  274435|           satyan|                null|     Karnataka|Bengaluru|       84|     2153|             3|     8| null|    145|            53|\n",
      "| 7721759|   TakeoffAndroid|             Takeoff|    Tamil Nadu|  Chennai|      112|     2136|             1|    18| null|    294|             2|\n",
      "|  338585|      Manishearth|           @mozilla |   Maharashtra|   Mumbai|      459|     2008|           116|   714|   91|  11765|          4401|\n",
      "|10007129|     ironmaniiith|https://www.youtu...|Andhra Pradesh|Hyderabad|       47|     1989|             3|    44|    2|  43279|           322|\n",
      "| 1942872|    varshylmobile|Varshyl Mobile Pv...|          null|     null|      138|     1977|            21|     1|    1|    153|          null|\n",
      "| 3692893|          ritz078|         Housing.com|   Maharashtra|   Mumbai|       91|     1966|             9|   148|    4|   2543|           271|\n",
      "| 7391618|          sharish|                null|    Tamil Nadu|  Chennai|       64|     1965|          null|     1| null|     65|            19|\n",
      "| 3097802|        bitshadow|                null|     Karnataka|Bengaluru|       69|     1940|             4|    13|    1|    340|           104|\n",
      "| 3475919|       debugger22|  BITS Pilani, India|   Maharashtra|   Mumbai|      264|     1916|            15|   105|    4|   1465|           590|\n",
      "| 2416560|         titu1994|                null|          null|     null|       57|     1903|            17|     7| null|   1649|           198|\n",
      "|  269639|         kirang89|     WalletKit, Inc.|    Tamil Nadu|     null|      288|     1874|            22|    34|    3|    973|            59|\n",
      "|  956749|           mayuur|                null|       Gujarat|Ahmadabad|       88|     1861|             5|     4| null|    103|             1|\n",
      "| 4612622|     ManrajGrover|Practo Technologi...|     Karnataka|Bengaluru|      181|     1831|            20|   214|    3|   2370|           218|\n",
      "| 1305514|            jpuri|              Humble|         Delhi|New Delhi|       33|     1761|            13|   104|    2|   2569|          1110|\n",
      "| 3254200|        arvindr21|    The IoT Suitcase|Andhra Pradesh|Hyderabad|      669|     1757|            78|    37|    1|   1290|            86|\n",
      "|  972811|         amitkaps|            amitkaps|     Karnataka|Bengaluru|       64|     1745|            12|     7| null|   1110|            73|\n",
      "| 5958931|        vipulasri|                null|         Delhi|New Delhi|       55|     1691|             2|    73| null|    142|            22|\n",
      "| 3889952|       ganapativs|              Tracxn|     Karnataka|Bengaluru|       14|     1671|             6|    14| null|   1159|            53|\n",
      "+--------+-----------------+--------------------+--------------+---------+---------+---------+--------------+------+-----+-------+--------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_more = utils.read_csv(spark, \"hdfs:/users_more.csv\")\n",
    "users = utils.read_csv(spark, \"hdfs:/users.csv\")\n",
    "\n",
    "users = (\n",
    "    users\n",
    "    .where(\n",
    "          (users.type == \"USR\")\n",
    "        & (users.deleted == 0)\n",
    "        & (users.fake == 0)\n",
    "        & (users.country_code == \"in\")\n",
    "    )\n",
    "    .withColumnRenamed(\"id\", \"user_id\")\n",
    "    .select(\"user_id\", \"login\", \"company\", \"state\", \"city\")\n",
    ")\n",
    "\n",
    "users_more = (\n",
    "    users_more\n",
    "    .select(\"user_id\", \"followers\", \"has_stars\", \"contributes_to\", \"issues\", \"pulls\", \"commits\", \"commits_others\")\n",
    ")\n",
    "\n",
    "user_new = (\n",
    "    users\n",
    "    .join(users_more, \"user_id\", \"left\")\n",
    ")\n",
    "\n",
    "top = (\n",
    "    user_new\n",
    "#     .orderBy(\"followers\", ascending=False)\n",
    "    .orderBy(\"has_stars\", ascending=False)\n",
    "#     .orderBy(\"contributes_to\", ascending=False)\n",
    ")\n",
    "\n",
    "top.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_more = utils.read_csv(spark, \"hdfs:/users_more.csv\")\n",
    "users = utils.read_csv(spark, \"hdfs:/users.csv\")\n",
    "\n",
    "users = (\n",
    "    users\n",
    "    .withColumnRenamed(\"id\", \"user_id\")\n",
    "#     .select(\"user_id\", \"login\", \"company\", \"state\", \"city\")\n",
    ")\n",
    "\n",
    "users_more = (\n",
    "    users_more\n",
    "#     .select(\"user_id\", \"followers\", \"has_stars\", \"contributes_to\", \"issues\", \"pulls\", \"commits\", \"commits_others\")\n",
    ")\n",
    "\n",
    "res = (\n",
    "    users\n",
    "    .join(users_more, \"user_id\", \"left\")\n",
    ")\n",
    "\n",
    "res.write.csv(\n",
    "    \"hdfs:/users_with_more\",\n",
    "    nullValue=\"\\\\N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commits Punchcard for top users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits = utils.read_csv(spark, \"hdfs:/commits_new.csv\")\n",
    "projects = utils.read_csv(spark, \"hdfs:/projects_new.csv\")\n",
    "\n",
    "# top_users = [5203, 896, 376498, 6240, 1779, 9236, 1570, 3871, 1736, 13009, 24452, 616741, 2468643, 2427, 81423, 796, 10005, 417948, 2016667, 1954]\n",
    "jamians = [1432224, 5107602, 4007006, 6145009, 2859386, 4925305, 2549876]\n",
    "\n",
    "res = (\n",
    "    commits\n",
    "    .where(\n",
    "        (commits.created_at.isNotNull())\n",
    "#         & (commits.author_id.isin(top_users))\n",
    "        & (commits.author_id.isin(jamians))\n",
    "    )\n",
    "    .select(\n",
    "        \"author_id\",\n",
    "        F.date_format('created_at', 'E').alias('day'),\n",
    "        F.hour('created_at').alias('hour')\n",
    "    )\n",
    "   .groupBy(\n",
    "    'author_id',\n",
    "    'day',\n",
    "    'hour'\n",
    "   )\n",
    "   .count()\n",
    "   .withColumnRenamed(\"count\", \"commits\")\n",
    "#    .withColumnRenamed(\"author_id\", \"user_id\")\n",
    ")\n",
    "\n",
    "res.write.json(\n",
    "    \"hdfs:/jamians_commit_punchcard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commits Punchcard for EVERYONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (\n",
    "    commits\n",
    "    .where(\n",
    "        (commits.created_at.isNotNull())\n",
    "    )\n",
    "    .select(\n",
    "        F.date_format('created_at', 'E').alias('day'),\n",
    "        F.hour('created_at').alias('hour')\n",
    "    )\n",
    "   .groupBy(\n",
    "    'day',\n",
    "    'hour'\n",
    "   )\n",
    "   .count()\n",
    "   .withColumnRenamed(\"count\", \"commits\")\n",
    ")\n",
    "\n",
    "res.write.json(\n",
    "    \"hdfs:/commit_punchcard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projects (More Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects =  utils.read_csv(spark, \"hdfs:/projects_new.csv\")\n",
    "stars = utils.read_csv(spark, \"hdfs:/watchers.csv\")\n",
    "issues = utils.read_csv(spark, \"hdfs:/issues.csv\")\n",
    "\n",
    "pcommits = utils.read_csv(spark, \"hdfs:/project_commit_count.csv\")\n",
    "pcommits_others = utils.read_csv(spark, \"hdfs:/project_commit_others_count.csv\")\n",
    "\n",
    "members = utils.read_csv(spark, \"hdfs:/project_members_new.csv\")\n",
    "\n",
    "# Find stars on a repo\n",
    "pstars = (\n",
    "    stars\n",
    "    .groupby(\"repo_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"stars\")\n",
    "    .withColumnRenamed(\"repo_id\", \"project_id\")\n",
    ")\n",
    "\n",
    "# Find forks of a repo\n",
    "pforks = (\n",
    "    projects\n",
    "    .where(projects.forked_from.isNotNull())\n",
    "    .groupby(\"forked_from\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"forks\")\n",
    "    .withColumnRenamed(\"forked_from\", \"project_id\")\n",
    ")\n",
    "\n",
    "# Find total issues on a repo\n",
    "pissues = (\n",
    "    issues\n",
    "    .where(issues.pull_request_id.isNull())\n",
    "    .groupby(\"repo_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"issues\")\n",
    "    .withColumnRenamed(\"repo_id\", \"project_id\")\n",
    ")\n",
    "\n",
    "# Find pull requests on a repo\n",
    "ppullreqs = (\n",
    "    issues\n",
    "    .where(issues.pull_request_id.isNotNull())\n",
    "    .groupby(\"repo_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"pull_requests\")\n",
    "    .withColumnRenamed(\"repo_id\", \"project_id\")\n",
    ")\n",
    "\n",
    "# Find members of a repo\n",
    "pmembers = (\n",
    "    members\n",
    "    .groupby(\"project_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"contributors\")\n",
    ")\n",
    "\n",
    "# Join Data\n",
    "pmore = (\n",
    "    pstars\n",
    "    .join(pforks, \"project_id\", \"full\")\n",
    "    .join(pmembers, \"project_id\", \"full\")\n",
    "    .join(pissues, \"project_id\", \"full\")\n",
    "    .join(ppullreqs, \"project_id\", \"full\")\n",
    "    .join(pcommits, \"project_id\", \"full\")\n",
    "    .join(pcommits_others, \"project_id\", \"full\")\n",
    ")\n",
    "\n",
    "# pmore.show()\n",
    "\n",
    "pmore.write.csv(\n",
    "    \"hdfs:/projects_more\",\n",
    "    mode=\"overwrite\",\n",
    "    nullValue=\"\\\\N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users (More Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = utils.read_csv(spark, \"hdfs:/issues.csv\")\n",
    "members = utils.read_csv(spark, \"hdfs:/project_members_new.csv\")\n",
    "\n",
    "user_more = utils.read_csv(spark, \"hdfs:/user_more.csv\")\n",
    "\n",
    "ucommits = utils.read_csv(spark, \"hdfs:/user_commit_count.csv\")\n",
    "ucommits_others = utils.read_csv(spark, \"hdfs:/user_commit_others_count.csv\")\n",
    "\n",
    "projects = utils.read_csv(spark, \"hdfs:/projects_new.csv\")\n",
    "projects_more = utils.read_csv(spark, \"hdfs:/projects_more\")\n",
    "\n",
    "projects.createOrReplaceTempView(\"projects\")\n",
    "projects_more.createOrReplaceTempView(\"projects_more\")\n",
    "\n",
    "# Find total stars that a users repos have recieved\n",
    "q = \"\"\"\n",
    "    SELECT P.owner_id as user_id, sum(M.stars) as stars_on_repos\n",
    "    FROM projects as P, projects_more as M\n",
    "    WHERE P.id = M.project_id\n",
    "    GROUP BY P.owner_id\n",
    "\"\"\"\n",
    "\n",
    "ustars = spark.sql(q)\n",
    "\n",
    "# Find total repos a user is members of\n",
    "umembers = (\n",
    "    members\n",
    "    .groupby(\"user_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"members_of_repos\")\n",
    ")\n",
    "\n",
    "\n",
    "# Find total issues by user\n",
    "uissues = (\n",
    "    issues\n",
    "    .where(issues.pull_request_id.isNull())\n",
    "    .groupby(\"reporter_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"issues\")\n",
    "    .withColumnRenamed(\"reporter_id\", \"user_id\")\n",
    ")\n",
    "\n",
    "# Find pull requests by user\n",
    "upullreqs = (\n",
    "    issues\n",
    "    .where(issues.pull_request_id.isNotNull())\n",
    "    .groupby(\"reporter_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"pull_requests\")\n",
    "    .withColumnRenamed(\"reporter_id\", \"user_id\")\n",
    ")\n",
    "\n",
    "# Join Data\n",
    "umore = (\n",
    "    user_more\n",
    "    .join(ustars, \"user_id\", \"full\")\n",
    "    .join(umembers, \"user_id\", \"full\")\n",
    "    .join(uissues, \"user_id\", \"full\")\n",
    "    .join(upullreqs, \"user_id\", \"full\")\n",
    "    .join(ucommits, \"user_id\", \"full\")\n",
    "    .join(ucommits_others, \"user_id\", \"full\")\n",
    ")\n",
    "\n",
    "umore.write.csv(\n",
    "    \"hdfs:/users_most\",\n",
    "    mode=\"overwrite\",\n",
    "    nullValue=\"\\\\N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[project_id: string, stars: bigint, forks: bigint, contributors: bigint, issues: bigint, pull_requests: bigint, commits: bigint, commits_by_others: bigint]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
