{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.types as spark_types\n",
    "import pyspark.sql.functions as sf\n",
    "\n",
    "def spark_schema_from_json(j):\n",
    "    return StructType([\n",
    "        StructField(\n",
    "            f[\"name\"],\n",
    "            spark_types._parse_datatype_string(f.get(\"type\", \"string\")),\n",
    "            f.get(\"nullable\", True),\n",
    "            f.get(\"metadata\", None)\n",
    "        )\n",
    "        for f in j\n",
    "    ])\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"GH Users\").getOrCreate()\n",
    "\n",
    "with open(\"ghtorrent-schema.json\") as f:\n",
    "    db_schema = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read projects.csv\n",
    "df_projects = spark.read.csv(\n",
    "    path=\"/home/hthuwal/Desktop/Ghtorrent_heads/projects.csv\",\n",
    "    schema=spark_schema_from_json(db_schema[\"projects.csv\"]),\n",
    "    nullValue=\"\\\\N\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read issues.csv\n",
    "df_issues = spark.read.csv(\n",
    "    path=\"/home/hthuwal/Desktop/Ghtorrent_heads/issues.csv\",\n",
    "    schema=spark_schema_from_json(db_schema[\"issues.csv\"]),\n",
    "    nullValue=\"\\\\N\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read commits.csv\n",
    "df_commits = spark.read.csv(\n",
    "    path=\"/home/hthuwal/Desktop/Ghtorrent_heads/commits.csv\",\n",
    "    schema=spark_schema_from_json(db_schema[\"commits.csv\"]),\n",
    "    nullValue=\"\\\\N\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pull_requests.csv\n",
    "df_pull_requests = spark.read.csv(\n",
    "    path=\"/home/hthuwal/Desktop/Ghtorrent_heads/pull_requests.csv\",\n",
    "    schema=spark_schema_from_json(db_schema[\"pull_requests.csv\"]),\n",
    "    nullValue=\"\\\\N\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pull_request_history.csv\n",
    "df_pull_request_history = spark.read.csv(\n",
    "    path=\"/home/hthuwal/Desktop/Ghtorrent_heads/pull_request_history.csv\",\n",
    "    schema=spark_schema_from_json(db_schema[\"pull_request_history.csv\"]),\n",
    "    nullValue=\"\\\\N\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifespan of projects based on commits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|project_id|duration|\n",
      "+----------+--------+\n",
      "|    646812|   15589|\n",
      "|     26340|   15588|\n",
      "|    688528|   15587|\n",
      "|    703528|   15585|\n",
      "|    331548|   15583|\n",
      "|    642580|   15583|\n",
      "|    149978|   15583|\n",
      "|     19275|   15566|\n",
      "|    193164|   15562|\n",
      "|    143064|   15561|\n",
      "|     59931|   15554|\n",
      "|     18215|   15536|\n",
      "|    202787|   15531|\n",
      "|    162304|   15457|\n",
      "|     50473|   15380|\n",
      "|    333497|   15240|\n",
      "|    447436|   15173|\n",
      "|    782192|   15156|\n",
      "|    633117|   14993|\n",
      "|     57532|   14666|\n",
      "+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first and last commit per project\n",
    "df_commits.createOrReplaceTempView(\"temp\")\n",
    "lifespan_commits = spark.sql(\"\"\"SELECT project_id, \n",
    "                      min(created_at) as first,\n",
    "                      max(created_at) as last\n",
    "                      FROM temp\n",
    "                      WHERE\n",
    "                      created_at < CURRENT_TIMESTAMP\n",
    "                      AND project_id IS NOT NULL\n",
    "                      GROUP BY project_id\n",
    "                      \"\"\"\n",
    ")\n",
    "lifespan_commits = lifespan_commits.withColumn('duration', sf.datediff(sf.col(\"last\"),sf.col(\"first\"))) \\\n",
    "                   .select(\"project_id\", \"duration\").sort(sf.desc(\"duration\"))\n",
    "lifespan_commits.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifespan of projects based on issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|project_id|duration|\n",
      "+----------+--------+\n",
      "|    825924|    1969|\n",
      "|     32678|    1716|\n",
      "|     32023|    1636|\n",
      "|      1334|    1615|\n",
      "|      1707|    1611|\n",
      "|     33145|    1609|\n",
      "|      1043|    1599|\n",
      "|   3746639|    1598|\n",
      "|      1678|    1598|\n",
      "|      6584|    1598|\n",
      "|     12558|    1597|\n",
      "|     28304|    1597|\n",
      "|       411|    1597|\n",
      "|      6883|    1596|\n",
      "|     57415|    1595|\n",
      "|       189|    1595|\n",
      "|      5245|    1594|\n",
      "|    269963|    1594|\n",
      "|     72295|    1593|\n",
      "|      7894|    1593|\n",
      "+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first and last issue per project\n",
    "df_issues.createOrReplaceTempView(\"temp\")\n",
    "lifespan_issues = spark.sql(\"\"\"SELECT repo_id as project_id,\n",
    "                      min(created_at) as first,\n",
    "                      max(created_at) as last\n",
    "                      FROM temp\n",
    "                      WHERE created_at < CURRENT_TIMESTAMP\n",
    "                      AND repo_id IS NOT NULL\n",
    "                      GROUP BY repo_id\n",
    "                      \"\"\"\n",
    ")\n",
    "lifespan_issues = lifespan_issues.withColumn('duration', sf.datediff(sf.col(\"last\"),sf.col(\"first\"))) \\\n",
    "                   .select(\"project_id\", \"duration\").sort(sf.desc(\"duration\"))\n",
    "lifespan_issues.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifespan of project based on pull request activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|pull_request_id|   last_action_time|\n",
      "+---------------+-------------------+\n",
      "|        2922704|2014-02-04 23:53:19|\n",
      "|        2542092|2014-02-04 23:53:12|\n",
      "|        2754127|2014-02-04 23:47:51|\n",
      "|        2925089|2014-02-04 23:34:39|\n",
      "|        2924069|2014-02-04 23:00:53|\n",
      "|        2864099|2014-02-04 22:55:40|\n",
      "|        2913490|2014-02-04 22:43:24|\n",
      "|        2916280|2014-02-04 22:39:29|\n",
      "|         133323|2014-02-04 22:10:28|\n",
      "|        2889989|2014-02-04 22:06:13|\n",
      "|        2919026|2014-02-04 21:59:10|\n",
      "|        2872286|2014-02-04 21:55:03|\n",
      "|        2743840|2014-02-04 21:53:25|\n",
      "|        2504948|2014-02-04 21:39:08|\n",
      "|        2485363|2014-02-04 21:22:29|\n",
      "|        2813838|2014-02-04 21:19:57|\n",
      "|        2584093|2014-02-04 21:15:13|\n",
      "|        2885327|2014-02-04 21:02:52|\n",
      "|        2881601|2014-02-04 20:56:44|\n",
      "|        2928250|2014-02-04 20:55:50|\n",
      "+---------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# last action of each pull request\n",
    "last_act_plreq = df_pull_request_history \\\n",
    "                               .groupBy(df_pull_request_history.pull_request_id) \\\n",
    "                               .agg(sf.max(df_pull_request_history.created_at).alias('last_action_time')) \\\n",
    "                               .sort(sf.desc(\"last_action_time\"))\n",
    "last_act_plreq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-------------------+\n",
      "|head_repo_id|base_repo_id|   last_action_time|\n",
      "+------------+------------+-------------------+\n",
      "|     6013443|     5940987|2014-02-04 23:53:19|\n",
      "|     6680430|     1958118|2014-02-04 23:53:12|\n",
      "|     7247086|     6031587|2014-02-04 23:47:51|\n",
      "|     7749253|     7340343|2014-02-04 23:34:39|\n",
      "|     7746587|       82594|2014-02-04 23:00:53|\n",
      "|     7579868|     1356577|2014-02-04 22:55:40|\n",
      "|     7249635|     7249635|2014-02-04 22:43:24|\n",
      "|     6193996|     6184871|2014-02-04 22:39:29|\n",
      "|      382315|      174554|2014-02-04 22:10:28|\n",
      "|     6307316|     6307316|2014-02-04 22:06:13|\n",
      "|     7730159|     4736847|2014-02-04 21:59:10|\n",
      "|      795282|      139327|2014-02-04 21:55:03|\n",
      "|     5049920|     5049920|2014-02-04 21:53:25|\n",
      "|     6328603|     1905872|2014-02-04 21:39:08|\n",
      "|     4511467|     4346078|2014-02-04 21:22:29|\n",
      "|     7436039|     2418719|2014-02-04 21:19:57|\n",
      "|     6421675|     6199549|2014-02-04 21:15:13|\n",
      "|     2207012|     2207012|2014-02-04 21:02:52|\n",
      "|     4179265|     4021035|2014-02-04 20:56:44|\n",
      "|     7756497|     2604327|2014-02-04 20:55:50|\n",
      "+------------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df_pull_requests.alias(\"df1\")\n",
    "df2 = last_act_plreq.alias(\"df2\")\n",
    "\n",
    "# last action of pull request per (base repo, head repo)\n",
    "df_temp = df1.join(df2, sf.col(\"df1.id\") == sf.col(\"df2.pull_request_id\"),\"inner\") \\\n",
    "          .select(df1.head_repo_id, df1.base_repo_id, df2.last_action_time) \\\n",
    "          .where(df1.head_repo_id.isNotNull() & df1.base_repo_id.isNotNull()) \\\n",
    "          .sort(sf.desc(\"last_action_time\"))\n",
    "          \n",
    "df_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|project_id|   last_action_time|\n",
      "+----------+-------------------+\n",
      "|   6013443|2014-02-04 23:53:19|\n",
      "|   6680430|2014-02-04 23:53:12|\n",
      "|   7247086|2014-02-04 23:47:51|\n",
      "|   7749253|2014-02-04 23:34:39|\n",
      "|   7746587|2014-02-04 23:00:53|\n",
      "|   7579868|2014-02-04 22:55:40|\n",
      "|   7249635|2014-02-04 22:43:24|\n",
      "|   6193996|2014-02-04 22:39:29|\n",
      "|    382315|2014-02-04 22:10:28|\n",
      "|   6307316|2014-02-04 22:06:13|\n",
      "|   7730159|2014-02-04 21:59:10|\n",
      "|    795282|2014-02-04 21:55:03|\n",
      "|   5049920|2014-02-04 21:53:25|\n",
      "|   6328603|2014-02-04 21:39:08|\n",
      "|   4511467|2014-02-04 21:22:29|\n",
      "|   7436039|2014-02-04 21:19:57|\n",
      "|   6421675|2014-02-04 21:15:13|\n",
      "|   2207012|2014-02-04 21:02:52|\n",
      "|   4179265|2014-02-04 20:56:44|\n",
      "|   7756497|2014-02-04 20:55:50|\n",
      "+----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp.createOrReplaceTempView(\"temp\")\n",
    "\n",
    "# takes two passes need to do in single pass\n",
    "query = \"\"\" \n",
    "            SELECT temp.head_repo_id as project_id, temp.last_action_time \n",
    "            FROM temp WHERE temp.head_repo_id IS NOT NULL\n",
    "            UNION ALL\n",
    "            SELECT temp.base_repo_id as project_id, temp.last_action_time \n",
    "            FROM temp WHERE temp.base_repo_id IS NOT NULL\n",
    "        \"\"\"\n",
    "# last pull activity per repo\n",
    "last_pull_act_repo = spark.sql(query)\n",
    "last_pull_act_repo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|project_id|duration|\n",
      "+----------+--------+\n",
      "|    251975|    1249|\n",
      "|       770|    1247|\n",
      "|     18474|    1243|\n",
      "|     22810|    1242|\n",
      "|    499790|    1242|\n",
      "|     48582|    1242|\n",
      "|     23830|    1241|\n",
      "|    390616|    1241|\n",
      "|     50331|    1239|\n",
      "|       634|    1238|\n",
      "|      1920|    1237|\n",
      "|      3826|    1235|\n",
      "|     53603|    1235|\n",
      "|     91833|    1233|\n",
      "|     14073|    1233|\n",
      "|       183|    1232|\n",
      "|     35079|    1230|\n",
      "|        37|    1230|\n",
      "|      5219|    1229|\n",
      "|    552190|    1225|\n",
      "+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first and last pull_request activity\n",
    "last_pull_act_repo.createOrReplaceTempView(\"temp\")\n",
    "lifespan_pulls = spark.sql(\"\"\"SELECT project_id,\n",
    "                      min(last_action_time) as first,\n",
    "                      max(last_action_time) as last\n",
    "                      FROM temp\n",
    "                      WHERE last_action_time < CURRENT_TIMESTAMP\n",
    "                      AND project_id IS NOT NULL\n",
    "                      GROUP BY project_id\n",
    "                      \"\"\"\n",
    ")\n",
    "lifespan_pulls = lifespan_pulls.withColumn('duration', sf.datediff(sf.col(\"last\"),sf.col(\"first\"))) \\\n",
    "                   .select(\"project_id\", \"duration\").sort(sf.desc(\"duration\"))\n",
    "lifespan_pulls.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifespan single table and reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects.createOrReplaceTempView(\"temp\")\n",
    "lifespan_commits.createOrReplaceTempView(\"t1\")\n",
    "lifespan_issues.createOrReplaceTempView(\"t2\")\n",
    "lifespan_pulls.createOrReplaceTempView(\"t3\")\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT temp.url, temp.owner_id, temp.language,\n",
    "           t1.duration as commits, t2.duration as issues, t3.duration as pull_requests\n",
    "    FROM temp, t1, t2, t3\n",
    "\"\"\"\n",
    "\n",
    "lifespan = spark.sql(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
