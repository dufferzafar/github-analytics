{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.types as spark_types\n",
    "\n",
    "import utils\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"GH Users\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = utils.read_csv(spark, path=\"/mnt/Data/GHTorrent/users.csv\")\n",
    "users = df\n",
    "\n",
    "# df.count()\n",
    "\n",
    "# Users who have perfectly mapped location data\n",
    "df2 = df.filter(df.country_code.isNotNull())\n",
    "# df2.count()\n",
    "\n",
    "# Users who have data in location field but which couldn't be mapped to a\n",
    "# country etc.\n",
    "# df3 = df.filter(df.country_code.isNull() & df.location.isNotNull())\n",
    "\n",
    "# df3.count()\n",
    "\n",
    "# Such users from India?\n",
    "# df4 = df3.filter(df.location.rlike(\"\\\\bIndia\\\\b\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Companies with most GitHub users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# People who have a company\n",
    "not_really_companies = [\"NA\", \"N/A\", \"None\", \"none\", \"-\", \"Personal\", \"Student\", \"student\", \"self\", \"Self\", \"Home\", \"Freelance\", \"Freelancer\"]\n",
    "df_company = (\n",
    "    df\n",
    "    .where(\n",
    "        (df.company.isNotNull()) \n",
    "        & ~ (df.company.isin(not_really_companies)) \n",
    "        & ~ (df.company.contains(\"CLICK \"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# People who claim to be from India\n",
    "df5 = df_company.filter(df.location.rlike(\"\\\\bIndia\\\\b\"))\n",
    "\n",
    "# Count & Sort\n",
    "df6 = df_company.groupby(\"company\").count().sort(\"count\", ascending=False)\n",
    "\n",
    "# Which IIT is at the top?\n",
    "df6.filter(df.company.startswithith(\"IIT\")).show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Companies with most GitHub users\n",
    "\n",
    "df6 = df_company.groupby(\"company\").count().sort(\"count\", ascending=False)\n",
    "\n",
    "df6.show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users Year Country Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = (\n",
    "    df2\n",
    "    .select(F.year(df2.created_at).name(\"year\"), \"country_code\")\n",
    "    .groupby(\"year\", \"country_code\")\n",
    "    .count()\n",
    "    .sort(\"count\", ascending=False)\n",
    ")\n",
    "\n",
    "# df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df4.count()\n",
    "df4.coalesce(1).write.json(\"user-year-country-count.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "odf = pd.read_json(open(\"../outputs/user-year-country-count.json\"))\n",
    "odf = odf.loc[odf.year != 2017]\n",
    "# odf['year'] = pd.to_datetime(odf['year'], format=\"%Y\")\n",
    "\n",
    "# odf.head(50).country_code.unique()\n",
    "odf2 = odf.loc[odf.year == 2014]\n",
    "odf2.sort_values(\"count\")\n",
    "\n",
    "odf3 = odf2.head(20)\n",
    "\n",
    "# odf3.country_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "odf3.plot.bar(x=\"country_code\", y=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import output_notebook; output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show\n",
    "from bokeh.palettes import Spectral11\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "p = figure(\n",
    "    x_range=(odf3.country_code.unique()),\n",
    "    plot_height=500\n",
    ")\n",
    "\n",
    "p.vbar(\n",
    "    source=odf3, \n",
    "    \n",
    "    x='country_code', top='count', \n",
    "    width=1, \n",
    "    line_color='white', \n",
    "    fill_color=factor_cmap('country_code', palette=Spectral11, factors=odf3.country_code.unique())\n",
    ")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import HoverTool\n",
    "from bokeh.palettes import Spectral5\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"year\", \"$x{(0000)}\"),\n",
    "    (\"users\", \"$y{(0.00 a)}\"),\n",
    "])\n",
    "\n",
    "p = figure(plot_height=500, y_axis_label=\"No. of Users\", x_axis_label=\"Year\", title=\"No. of users in countries\")\n",
    "p.add_tools(hover)\n",
    "\n",
    "countries = [\"us\", \"in\", \"cn\", \"gb\", \"de\"]\n",
    "colors = Spectral5\n",
    "\n",
    "for i, country in enumerate(countries):\n",
    "    odf4 = odf.loc[odf.country_code == country]\n",
    "    odf4 = odf4.sort_values(\"year\")\n",
    "\n",
    "    x = odf4['year']\n",
    "    y = odf4['count']\n",
    "\n",
    "    color = colors[i % len(colors)]\n",
    "    \n",
    "    p.line(x, y, color=color, legend=country)\n",
    "    p.circle(x, y, fill_color=\"white\", size=8, color=color)\n",
    "\n",
    "\n",
    "p.legend.location = \"top_left\"\n",
    "    \n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where do Indian GitHub users live?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.filter(\n",
    "    df.country_code == \"in\"\n",
    ")\n",
    "\n",
    "# df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCR = [\"Delhi\", \"New Delhi\", \"Gurgaon\", \"Noida\", \"Faridabad\"]\n",
    "\n",
    "df4 = (\n",
    "    df3\n",
    "    .where(df3.state.isNotNull())\n",
    "#     .where(df3.city.isNotNull())\n",
    "#     .select(\"city\", F.when(df.city.isin(NCR), \"Delhi (NCR)\").otherwise(df.city).name(\"region\"))\n",
    "#     .select(\"city\")\n",
    "#     .groupby(\"region\")\n",
    "    .groupby(\"state\")\n",
    "    .count()\n",
    "    .sort(\"count\", ascending=False)\n",
    ")\n",
    "\n",
    "df4.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.coalesce(1).write.json(\"user-india-state-count.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Number of new users per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.limit(10).show()\n",
    "df3 = (\n",
    "    users\n",
    "    .where(users.created_at.isNotNull())\n",
    "    .select(F.year(users.created_at).name(\"year\"),\n",
    "            F.month(users.created_at).name(\"month\"))\n",
    "    .groupby(\"year\", \"month\")\n",
    "    .count()\n",
    "    .orderBy(\"count\", ascending=False)\n",
    ")\n",
    "\n",
    "# df3.show()\n",
    "df3.coalesce(1).write.json(\"user-year-month-count.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of followers of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers = spark.read.csv(\n",
    "    path=\"/mnt/Data/GHTorrent/followers.csv\",\n",
    "    schema=spark_schema_from_json(db_schema[\"followers.csv\"]),\n",
    "    nullValue=\"\\\\N\",\n",
    ")\n",
    "\n",
    "df2 = (\n",
    "    followers\n",
    "    .groupby(\"follower_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"following\")\n",
    "    .withColumnRenamed(\"follower_id\", \"user_id\")\n",
    ")\n",
    "\n",
    "# print(df2.count())\n",
    "\n",
    "df3 = (\n",
    "    followers\n",
    "    .groupby(\"user_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"followers\")\n",
    ")\n",
    "\n",
    "# print(df3.count())\n",
    "\n",
    "# df5 = df2.join(df3, \"user_id\", \"full\")\n",
    "\n",
    "# df5.limit(100).show(100)\n",
    "\n",
    "# print(df5.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of repositories starred by each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stars were previously called watchers\n",
    "stars = spark.read.csv(\n",
    "    path=\"/mnt/Data/GHTorrent/watchers.csv\",\n",
    "    schema=spark_schema_from_json(db_schema[\"watchers.csv\"]),\n",
    "    nullValue=\"\\\\N\",\n",
    ")\n",
    "\n",
    "df4 = (\n",
    "    stars\n",
    "    .groupby(\"user_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"starred\")\n",
    ")\n",
    "\n",
    "df5 = df2.join(df3, \"user_id\", \"full\").join(df4, \"user_id\", \"full\")\n",
    "\n",
    "df5.write.csv(\n",
    "    \"user_more\",\n",
    "    mode=\"overwrite\",\n",
    "    nullValue=\"\\\\N\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of repositories of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects =  utils.read_csv(spark, \"/mnt/Data/GHTorrent/projects_new.csv\")\n",
    "user_more =  utils.read_csv(spark, \"/mnt/Data/GHTorrent/user_more.csv\")\n",
    "\n",
    "# Find source repos\n",
    "df4 = (\n",
    "    projects\n",
    "    .where(projects.deleted == 0 & projects.forked_from.isNull())\n",
    "    .groupby(\"owner_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"repos_source\")\n",
    "    .withColumnRenamed(\"owner_id\", \"user_id\")\n",
    ")\n",
    "\n",
    "# Find forks\n",
    "df6 = (\n",
    "    projects\n",
    "    .where(projects.deleted == 0 & projects.forked_from.isNotNull())\n",
    "    .groupby(\"owner_id\")\n",
    "    .count()\n",
    "    .withColumnRenamed(\"count\", \"repos_forks\")\n",
    "    .withColumnRenamed(\"owner_id\", \"user_id\")\n",
    ")\n",
    "\n",
    "# Join Data\n",
    "df5 = user_more.join(df4, \"user_id\", \"full\").join(df6, \"user_id\", \"full\")\n",
    "\n",
    "# Write to local directory\n",
    "df5.write.csv(\n",
    "    \"../user_more_2\",\n",
    "    mode=\"overwrite\",\n",
    "    nullValue=\"\\\\N\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
